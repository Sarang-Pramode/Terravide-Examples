{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import laspy\n",
    "import json\n",
    "import pptk\n",
    "from math import *\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import path\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.neighbors import KDTree\n",
    "import alphashape\n",
    "from shapely.geometry import Point\n",
    "from scipy.spatial import ConvexHull\n",
    "from pysolar.solar import *\n",
    "import datetime\n",
    "import csv\n",
    "import pytz\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "from pyproj import Transformer\n",
    "\n",
    "\n",
    "# from ipywidgets import IntProgress\n",
    "# from IPython.display import display\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "#HARDCODED VALUES\n",
    "\n",
    "COLOR_DICT = {\n",
    "    \"WHITE\" : [255,255,255],\n",
    "    \"RED\" : [1,0,0],\n",
    "    \"GREEN\" : [0,1,0],\n",
    "    \"BLUE\" : [0,0,1],\n",
    "    \"YELLOW\" : [255,255,0],\n",
    "    \"LIGHT_BLUE\" : [0,255,255],\n",
    "    \"PINK\" : [255,0,255]\n",
    "}\n",
    "\n",
    "DATE_DICT = {\n",
    "    \"YEAR\" : 2021,\n",
    "    \"MONTH\" : 6,\n",
    "    \"DAY\" : 21\n",
    "}\n",
    "\n",
    "\n",
    "def Create_Dataframe_fromLas(lasFilePath):\n",
    "    las = laspy.read(lasFilePath)\n",
    "    #point_format = las.point_format\n",
    "    lidar_points = np.array((las.X,las.Y,las.Z,las.intensity,las.classification, las.return_number, las.number_of_returns)).transpose()\n",
    "    lidar_df = pd.DataFrame(lidar_points)\n",
    "    lidar_df[0] = lidar_df[0]/100\n",
    "    lidar_df[1] = lidar_df[1]/100\n",
    "    lidar_df[2] = lidar_df[2]/100\n",
    "    lidar_df.columns = ['X', 'Y', 'Z', 'intens', 'class', 'return_number', 'number_of_returns']\n",
    "    \n",
    "    return lidar_df\n",
    "\n",
    "def Extract_SRdata(SR_JSONarr):\n",
    "    #Store all Raw Treepoints\n",
    "    SR_RawTreePoints = []\n",
    "    #Store all Tree points mapped to a Tree ID\n",
    "    SR_TreeClusterDict = {}\n",
    "    #Store Tree Heights\n",
    "    TreeHeights_ClusterHashmap = {}\n",
    "    #Store GroundZ Elevation\n",
    "    GroundElevation_ClusterHashmap = {}\n",
    "    #Store All Tree Ids\n",
    "    JSONClusterID_SR = []\n",
    "\n",
    "    for i in range(len(SR_JSONarr)):\n",
    "        #get points and cluster ID\n",
    "        points = SR_JSONarr[i][\"SRpointsInfo\"][\"SpecificClusterSRpoints\"]\n",
    "        cluster_id = SR_JSONarr[i]['SRpointsInfo']['SRpointsTreeCluster']\n",
    "        #Storing with Cluster ID hashmap prevents storing multiple points from the same tree, if Tree present\n",
    "        if cluster_id not in SR_TreeClusterDict:\n",
    "            SR_TreeClusterDict[cluster_id] = points\n",
    "        else:\n",
    "            for p in points: \n",
    "                SR_TreeClusterDict[cluster_id].append(p)\n",
    "        #Tree Heights\n",
    "        if cluster_id not in TreeHeights_ClusterHashmap:\n",
    "            TreeHeights_ClusterHashmap[cluster_id] = SR_JSONarr[i]['TreeFoliageHeight']\n",
    "        #GroundZvalue\n",
    "        if cluster_id not in GroundElevation_ClusterHashmap:\n",
    "            GroundElevation_ClusterHashmap[cluster_id] = SR_JSONarr[i]['GroundZValue']\n",
    "\n",
    "        #Raw Points\n",
    "        for j in points:\n",
    "            SR_RawTreePoints.append(j)\n",
    "\n",
    "    return SR_RawTreePoints, SR_TreeClusterDict, TreeHeights_ClusterHashmap, GroundElevation_ClusterHashmap\n",
    "\n",
    "def Extract_MRdata(MR_JSONarr):\n",
    "    ##Store all Raw Treepoints\n",
    "    MR_RawTreePoints = []\n",
    "    #Store all Tree points mapped to a Tree ID\n",
    "    MR_TreeClusterDict = {}\n",
    "    #Store Cluster Location\n",
    "    TreeLocation_ClusterHashmap = {}\n",
    "    \n",
    "    for i in range(len(MR_JSONarr)):\n",
    "        #get points and cluster ID\n",
    "        points = MR_JSONarr[i][\"ConvexHullDict\"][\"ClusterPoints\"]\n",
    "        cluster_id = MR_JSONarr[i]['ClusterID']\n",
    "        #Storing with Cluster ID hashmap prevents storing multiple points from the same tree, if Tree present\n",
    "        if cluster_id not in MR_TreeClusterDict:\n",
    "            MR_TreeClusterDict[cluster_id] = points\n",
    "        else:\n",
    "            for p_mr in points: \n",
    "                MR_TreeClusterDict[cluster_id].append(p_mr)\n",
    "\n",
    "        Tree_lat = MR_JSONarr[i][\"PredictedTreeLocation\"][\"Latitude\"]\n",
    "        Tree_long = MR_JSONarr[i][\"PredictedTreeLocation\"][\"Longitude\"]\n",
    "\n",
    "        if cluster_id not in TreeLocation_ClusterHashmap:\n",
    "            TreeLocation_ClusterHashmap[cluster_id] = [Tree_lat,Tree_long]\n",
    "\n",
    "        #Raw points\n",
    "        for k in points:\n",
    "            MR_RawTreePoints.append(k)\n",
    "    \n",
    "    return MR_RawTreePoints, MR_TreeClusterDict, TreeLocation_ClusterHashmap\n",
    "\n",
    "def Get_SR_Treepoints_from_Hashmap(TreeClusterID, SR_TreeClusterDict, las_filename='25192'):\n",
    "    return SR_TreeClusterDict[las_filename+\"_\"+str(TreeClusterID)]\n",
    "\n",
    "def Get_MR_Treepoints_from_Hashmap(TreeClusterID, MR_TreeClusterDict, las_filename='25192'):\n",
    "    return MR_TreeClusterDict[las_filename+\"_\"+str(TreeClusterID)]\n",
    "\n",
    "def Get_FullTree_points(TreeClusterArr, SR_TreeClusterDict, MR_TreeClusterDict, Ground_Elevation = 0, Tree_Height = 0):\n",
    "    Full_Tree = []\n",
    "    for Tree_Id in TreeClusterArr:\n",
    "        TreePoints_SR = Get_SR_Treepoints_from_Hashmap(Tree_Id,SR_TreeClusterDict)\n",
    "        TreePoints_MR = Get_MR_Treepoints_from_Hashmap(Tree_Id,MR_TreeClusterDict)\n",
    "        All_SingleTree_points = np.concatenate((TreePoints_MR,TreePoints_SR), axis=0)\n",
    "        All_SingleTree_points = All_SingleTree_points*3.28 # Convert m to ft\n",
    "        for p in All_SingleTree_points:\n",
    "            Full_Tree.append(p - [0,0,Ground_Elevation+Tree_Height]) #Height Adjusted, default = 0\n",
    "            \n",
    "    return np.array(Full_Tree)\n",
    "\n",
    "def Get_FullTreeCentroid(Full_Tree_points):\n",
    "    centroid = np.mean(Full_Tree_points,axis=0)\n",
    "    centroid[2] = 0\n",
    "\n",
    "    return centroid\n",
    "\n",
    "def Get_Shadow(points, az, amp):\n",
    "    projected_points = []\n",
    "    for point in points:\n",
    "        sinAz = sin( radians( az + 180.0 ) )\n",
    "        cosAz = cos( radians( az + 180.0 ) )\n",
    "        tanAmp = tan( radians(amp) )\n",
    "        pointGroundX = point[0] + ( ( point[2] / tanAmp ) *sinAz )\n",
    "        pointGroundY = point[1] + ( ( point[2] / tanAmp ) *cosAz )\n",
    "        pointGroundZ =  point[2] * 0\n",
    "    \n",
    "        projected_points.append([pointGroundX,pointGroundY,pointGroundZ])\n",
    "    \n",
    "    return np.array(projected_points)\n",
    "\n",
    "def Get_ShadowCharacteristics(Full_Tree, TreeShadow):\n",
    "\n",
    "    F_distance, F_point = Get_FurthestPointFromTreeCentroid(Full_Tree, TreeShadow)\n",
    "    centroid = Get_FullTreeCentroid(Full_Tree)\n",
    "    hull = ConvexHull(TreeShadow[:,:2])\n",
    "\n",
    "    Shadow_Area = hull.area\n",
    "    Shadow_length = np.linalg.norm(centroid - F_point) # Tree Centroid - Furthest point from Tree centroid on Tree shadow\n",
    "    shadow_breadth = Shadow_Area/Shadow_length\n",
    "\n",
    "    return Shadow_length, shadow_breadth, Shadow_Area\n",
    "\n",
    "def Get_FurthestPointFromTreeCentroid(Full_Tree, TreeShadow):\n",
    "    \n",
    "    Shadow_KDTree = KDTree(TreeShadow)\n",
    "    centroid = Get_FullTreeCentroid(Full_Tree)\n",
    "    dist,ind = Shadow_KDTree.query(centroid.reshape(1,3),len(TreeShadow))\n",
    "    \n",
    "    Furtherst_Point_Distance = dist[0][-1]\n",
    "    Furthest_Point_Vector = TreeShadow[ind[0][-1]]\n",
    "\n",
    "    return Furtherst_Point_Distance, Furthest_Point_Vector\n",
    "\n",
    "def Get_ShadowAlphaShape(ShadowPoints):\n",
    "    return alphashape.alphashape(ShadowPoints, alpha=0)\n",
    "\n",
    "# func v1\n",
    "# def Get_TreeLocation(TreeID, TreeID_Location_dict, las_filename='25192'):\n",
    "#     return TreeID_Location_dict[las_filename+\"_\"+str(TreeID)]\n",
    "# func_v2\n",
    "def Get_TreeLocation(json_dataBuffer):\n",
    "    lat = json_dataBuffer['PredictedTreeLocation']['Latitude']\n",
    "    lon = json_dataBuffer['PredictedTreeLocation']['Longitude']\n",
    "    return lat,lon\n",
    "\n",
    "def Get_TreeGroundElevation(TreeID, GroundElevation_ClusterDict, las_filename='25192'):\n",
    "    return GroundElevation_ClusterDict[las_filename+\"_\"+str(TreeID)]\n",
    "    \n",
    "def Get_TreeHeight(TreeID, TreeHeights_ClusterDict, las_filename='25192'):\n",
    "    return TreeHeights_ClusterDict[las_filename+\"_\"+str(TreeID)]\n",
    "\n",
    "def Get_GroundElevation(BuildingLidarDict):\n",
    "    arr = (np.concatenate(list(BuildingLidarDict.values())))\n",
    "    #Get ground elevation from building points min(list(BuildingLidarDict.values())[0][:,2])\n",
    "    return min(arr[:,2])\n",
    "\n",
    "#Code to automate Obtaining Az and Amp\n",
    "def Get_SunData(Tree_Latitude, Tree_Longitude, year, month, day, hour, minute):\n",
    "    date = datetime.datetime(year, month, day, hour, minute, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "    date_est = date.astimezone(pytz.timezone('US/Eastern')).isoformat()\n",
    "    az = get_azimuth(Tree_Latitude, Tree_Longitude, date)\n",
    "    amp = get_altitude(Tree_Latitude, Tree_Longitude, date)\n",
    "\n",
    "    return date_est, az, amp\n",
    "\n",
    "def pptk_wrapperSimplePlot(PointsArr, Color):\n",
    "    v = pptk.viewer(PointsArr, [Color]*len(PointsArr))\n",
    "    v.set(show_grid=False)\n",
    "    v.set(show_axis=False)\n",
    "    v.set(bg_color = [0,0,0,0])\n",
    "    v.set(point_size = 0.04)\n",
    "\n",
    "def sample_polygon(V, eps=0.25):\n",
    "    # samples polygon V s.t. consecutive samples are no greater than eps apart\n",
    "    # assumes last vertex in V is a duplicate of the first\n",
    "    M = np.ceil(np.sqrt(np.sum(np.diff(V, axis=0) ** 2, axis = 1)) / eps)\n",
    "    Q = []\n",
    "    for (m, v1, v2) in zip(M, V[: -1], V[1:]):\n",
    "        Q.append(np.vstack([ \\\n",
    "            np.linspace(v1[0], v2[0], endpoint = False), \\\n",
    "            np.linspace(v1[1], v2[1], endpoint = False)]).T)\n",
    "    Q = np.vstack(Q)\n",
    "\n",
    "    return Q\n",
    "\n",
    "def Read_GeoJSON(filepath):\n",
    "    with open(filepath, 'rb') as fd:\n",
    "        data = json.load(fd)\n",
    "\n",
    "    return data\n",
    "\n",
    "def Get_SampledBuildingFootprints(Buildingdata):\n",
    "    BuildingFeature_Coords = [np.array(F['geometry']['coordinates'][0][0]) for F in Buildingdata['features']]\n",
    "    SampledFootprint = np.vstack([sample_polygon(W) for W in BuildingFeature_Coords])\n",
    "    SampledFootprint = np.c_[SampledFootprint, np.zeros(len(SampledFootprint))]\n",
    "\n",
    "    return SampledFootprint\n",
    "\n",
    "def Get_BuildingFootprint(GeoJSON_Filepath):\n",
    "    BuidlingFootprintData = Read_GeoJSON(GeoJSON_Filepath)\n",
    "\n",
    "    return Get_SampledBuildingFootprints(BuidlingFootprintData)\n",
    "\n",
    "def Get_BuildingDataDict(BuildingFilePath, las_filename='25192', las_file_year=2015):\n",
    "    with open(BuildingFilePath, 'rb') as fd:\n",
    "        NYC_building_Footprint = json.load(fd)\n",
    "    \n",
    "    Vs_25192 = [np.array(F['geometry']['coordinates'][0][0]) for F in NYC_building_Footprint['features']]\n",
    "    ### **Note** : NYC points already projected to state plane, No need for pyproj\n",
    "    Ws_25192 = Vs_25192\n",
    "    Total_Building_Count = len(NYC_building_Footprint['features'])\n",
    "    #Building_Data_dict\n",
    "    Building_coords_dict = {}\n",
    "    B_ID = 0\n",
    "    Building_Key = las_filename + \"_\" + str(las_file_year) + \"_Building_\" + str(B_ID) # initialized to 25192_2015_Building_0\n",
    "\n",
    "    for building in range(Total_Building_Count):\n",
    "\n",
    "        B_ID += 1\n",
    "        Building_Key = las_filename + \"_\" + str(las_file_year) + \"_Building_\" + str(B_ID) # initialized to 25192_2015_Building_0\n",
    "        building_coords = sample_polygon(Ws_25192[building]) #NYC_building_Footprint['features'][building]['geometry']['coordinates'][0][0]\n",
    "        Building_coords_dict[Building_Key] = building_coords\n",
    "    \n",
    "    return Building_coords_dict\n",
    "\n",
    "#NOTE: Function takes most time\n",
    "def Get_BuildingsUnderEffectOfShadow(Building_coords_dict, TreeShadowPoints):\n",
    "    ShadowAlphaShape = Get_ShadowAlphaShape(TreeShadowPoints)\n",
    "    Affected_Building_IDarr = [] #Buildings Under the Direct Affect of the Shadow\n",
    "    for B_ID, Sampled_B_coords in Building_coords_dict.items():\n",
    "        bool_temp_list = []\n",
    "        for point in Sampled_B_coords:\n",
    "            tp = Point(point)\n",
    "            bool_temp_list.append(tp.within(ShadowAlphaShape))\n",
    "        #check if any points in the sampled footprint fall within the area of shadow\n",
    "        if len(Sampled_B_coords[bool_temp_list]) > 0:\n",
    "            Affected_Building_IDarr.append(B_ID)\n",
    "    \n",
    "    return Affected_Building_IDarr\n",
    "\n",
    "def Get_BuildingsUnderEffectOfShadow_Rapid(Building_coords_dict, TreeShadowPoints):\n",
    "\n",
    "    Affected_Building_IDarr = [] #Buildings Under the Direct Affect of the Shadow\n",
    "    for B_ID, Sampled_B_coords in Building_coords_dict.items():\n",
    "        bool_temp_list = []\n",
    "\n",
    "        p = path.Path(TreeShadowPoints[:,:2])\n",
    "        bool_temp_list = p.contains_points(Sampled_B_coords)\n",
    "        # #check if any points in the sampled footprint fall within the area of shadow\n",
    "        if len(Sampled_B_coords[bool_temp_list]) > 0:\n",
    "            Affected_Building_IDarr.append(B_ID)\n",
    "    \n",
    "    return Affected_Building_IDarr\n",
    "\n",
    "def Get_BuildingFootprintSampledCoords(BIDs_Arr, Building_coords_dict):\n",
    "\n",
    "    labelled_BF_points = []\n",
    "    for B_ID in BIDs_Arr:\n",
    "\n",
    "        b_points = Building_coords_dict[B_ID]\n",
    "\n",
    "        for p in b_points:\n",
    "            labelled_BF_points.append(p)\n",
    "\n",
    "    labelled_BF_points = np.array(labelled_BF_points) #shape : (Nx2)\n",
    "\n",
    "    #reformat for plotting purposes\n",
    "    LBF_arr = []\n",
    "    for cord in range(len(labelled_BF_points)):\n",
    "        x = labelled_BF_points[cord][0]\n",
    "        y = labelled_BF_points[cord][1]\n",
    "        z = 0\n",
    "        LBF_arr.append([x,y,z])\n",
    "\n",
    "    LBF_arr = np.array(LBF_arr)\n",
    "\n",
    "    return LBF_arr\n",
    "\n",
    "def Get_BuildingLidarPoints(BIDs_Arr, Building_coords_dict, lasdf):\n",
    "\n",
    "\n",
    "    lidarPointsRaw = lasdf.iloc[:,:3].to_numpy()\n",
    "    # Selecting Lidar Points within Building footprint\n",
    "\n",
    "    X_max , X_min = lasdf.X.max(), lasdf.X.min()\n",
    "    Y_max , Y_min = lasdf.Y.max(), lasdf.Y.min()\n",
    "\n",
    "    X_plane_tile_divisor = 50 #in m - indicates the number of tiles you want to divide the tiles into\n",
    "    Y_plane_tile_divisor = 50 #in m\n",
    "\n",
    "    X_diff = X_max - X_min\n",
    "    Y_diff = Y_max - Y_min\n",
    "\n",
    "    X_div_len = X_diff/X_plane_tile_divisor\n",
    "    Y_div_len = Y_diff/Y_plane_tile_divisor\n",
    "\n",
    "    # print(X_max , X_min)\n",
    "    # print(Y_max , Y_min)\n",
    "\n",
    "    #NOTE : Iterating over all the points takes too long, need a more optimized way \n",
    "\n",
    "    lidar_BpointsDict = {}\n",
    "\n",
    "    #For every building under the effect of the shadow\n",
    "    for B_ID in BIDs_Arr:\n",
    "\n",
    "        #List to append lidar points into for a specifc building\n",
    "        B_ID_LidarPointsTempList = []\n",
    "\n",
    "        #get the sampled building footprint points\n",
    "        bf_points = Building_coords_dict[B_ID]\n",
    "        \n",
    "\n",
    "        #create a 2D convex Hull\n",
    "        bf_shape = ConvexHull(bf_points[:,:2])\n",
    "\n",
    "        #Get an area of points to look at (No need to iterate through all points in the tile)\n",
    "        #get bounding subset to look at\n",
    "        bf_shape_X_max = bf_shape.max_bound[0] + X_div_len\n",
    "        bf_shape_Y_max = bf_shape.max_bound[1] + Y_div_len\n",
    "\n",
    "        bf_shape_X_min = bf_shape.min_bound[0] - X_div_len\n",
    "        bf_shape_Y_min = bf_shape.min_bound[1] - Y_div_len\n",
    "\n",
    "        # print(bf_shape_X_max,bf_shape_Y_max,bf_shape_X_min,bf_shape_Y_min)\n",
    "\n",
    "        #Bounded_Vertices_BF = bf_points[bf_shape.vertices]\n",
    "\n",
    "        lidar_subset_df = lasdf[\n",
    "            (lasdf['X'].between(bf_shape_X_min, bf_shape_X_max, inclusive=False) &\n",
    "        lasdf['Y'].between(bf_shape_Y_min, bf_shape_Y_max, inclusive=False))\n",
    "        ]\n",
    "\n",
    "        # print(\"subset shape : \",lidar_subset_df.shape)\n",
    "\n",
    "\n",
    "        #Get only points from BF\n",
    "        lidar_BFMasked_points = lidar_subset_df.iloc[:,:3].to_numpy()\n",
    "\n",
    "        #Check if a lidar point is within a building Footprint \n",
    "\n",
    "        #Add a z-coordinate to BF ,  needed for alphashape\n",
    "        bf_points_with_Z = np.c_[bf_points, np.zeros(len(bf_points))]\n",
    "        #Create a shape of the building footprint\n",
    "        bf_shape_alpha = alphashape.alphashape(bf_points_with_Z, alpha=0)\n",
    "\n",
    "        for p in lidar_BFMasked_points:\n",
    "            \n",
    "            tp = Point(p)\n",
    "            if(tp.within(bf_shape_alpha)):\n",
    "                B_ID_LidarPointsTempList.append(p)\n",
    "\n",
    "        if B_ID not in lidar_BpointsDict:\n",
    "            lidar_BpointsDict[B_ID] = np.array(B_ID_LidarPointsTempList)\n",
    "\n",
    "    return lidar_BpointsDict\n",
    "\n",
    "def Set_BuildingLidarHeightAdjustment(BuidlingDataDict, height_Adjustment):\n",
    "    \n",
    "    for B_ID, B_Lidarpoints in BuidlingDataDict.items():\n",
    "\n",
    "        bpArr = B_Lidarpoints\n",
    "        #adjust height of buildings\n",
    "        lidar_Bpoints_Hadj = []\n",
    "        for bp in bpArr:\n",
    "            lidar_Bpoints_Hadj.append(bp - [0,0,height_Adjustment])\n",
    "        \n",
    "        BuidlingDataDict[B_ID] = np.array(lidar_Bpoints_Hadj)\n",
    "    \n",
    "    return BuidlingDataDict\n",
    "\n",
    "\n",
    "#https://github.com/ulikoehler/UliEngineering/blob/master/UliEngineering/Math/Coordinates.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Estimating BOunding Box\n",
    "\"\"\"\n",
    "__all__ = [\"BoundingBox\"]\n",
    "\n",
    "class BoundingBox(object):\n",
    "    \"\"\"\n",
    "    A 2D bounding box\n",
    "    \"\"\"\n",
    "    def __init__(self, points):\n",
    "        \"\"\"\n",
    "        Compute the upright 2D bounding box for a set of\n",
    "        2D coordinates in a (n,2) numpy array.\n",
    "\n",
    "        You can access the bbox using the\n",
    "        (minx, maxx, miny, maxy) members.\n",
    "        \"\"\"\n",
    "        if len(points.shape) != 2 or points.shape[1] != 2:\n",
    "            raise ValueError(\"Points must be a (n,2), array but it has shape {}\".format(\n",
    "                points.shape))\n",
    "        if points.shape[0] < 1:\n",
    "            raise ValueError(\"Can't compute bounding box for empty coordinates\")\n",
    "        self.minx, self.miny = np.min(points, axis=0)\n",
    "        self.maxx, self.maxy = np.max(points, axis=0)\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        \"\"\"X-axis extent of the bounding box\"\"\"\n",
    "        return self.maxx - self.minx\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        \"\"\"Y-axis extent of the bounding box\"\"\"\n",
    "        return self.maxy - self.miny\n",
    "\n",
    "    @property\n",
    "    def area(self):\n",
    "        \"\"\"width * height\"\"\"\n",
    "        return self.width * self.height\n",
    "\n",
    "    @property\n",
    "    def aspect_ratio(self):\n",
    "        \"\"\"width / height\"\"\"\n",
    "        return self.width / self.height\n",
    "\n",
    "    @property\n",
    "    def center(self):\n",
    "        \"\"\"(x,y) center point of the bounding box\"\"\"\n",
    "        return (self.minx + self.width / 2, self.miny + self.height / 2)\n",
    "\n",
    "    @property\n",
    "    def max_dim(self):\n",
    "        \"\"\"The larger dimension: max(width, height)\"\"\"\n",
    "        return max(self.width, self.height)\n",
    "\n",
    "    @property\n",
    "    def min_dim(self):\n",
    "        \"\"\"The larger dimension: max(width, height)\"\"\"\n",
    "        return min(self.width, self.height)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BoundingBox({}, {}, {}, {})\".format(\n",
    "            self.minx, self.maxx, self.miny, self.maxy)\n",
    "    #NOTE: Added by me\n",
    "    def Get_Coords(self):\n",
    "        return [self.minx, self.maxx, self.miny, self.maxy]\n",
    "    \n",
    "\n",
    "def Get_TreeShadowBoundingBoxLimits(TreeShadow):\n",
    "    Box_obj = BoundingBox(TreeShadow[:,:2])\n",
    "    Box_Bounds = np.array(Box_obj.Get_Coords())\n",
    "\n",
    "    B_minx = Box_Bounds[0]\n",
    "    B_maxx = Box_Bounds[1]\n",
    "    B_miny = Box_Bounds[2]\n",
    "    B_maxy = Box_Bounds[3]\n",
    "\n",
    "    return B_minx, B_maxx, B_miny, B_maxy\n",
    "\n",
    "def Get_TreeShadowBoundingBoxesCoords(TreeShadow, Distance):\n",
    "\n",
    "    B_minx, B_maxx, B_miny, B_maxy = Get_TreeShadowBoundingBoxLimits(TreeShadow)\n",
    "\n",
    "    Tree_ShadowBox_Coords = [\n",
    "        [B_minx, B_miny, 0],\n",
    "        [B_minx, B_maxy, 0],\n",
    "        [B_maxx, B_maxy, 0],\n",
    "        [B_maxx, B_miny, 0],\n",
    "        [B_minx, B_miny, 0] # final one is to complete the box used for plotting purposes only\n",
    "    ]\n",
    "\n",
    "    Extend_dist = Distance #in m\n",
    "    Tree_ShadowBoxExtend_Coords = [\n",
    "        [B_minx, B_miny - Extend_dist, 0],\n",
    "        [B_minx, B_maxy, 0],\n",
    "        [B_maxx, B_maxy, 0],\n",
    "        [B_maxx, B_miny - Extend_dist, 0],\n",
    "        [B_minx, B_miny - Extend_dist, 0] # final one is to complete the box used for plotting purposes only\n",
    "    ]\n",
    "\n",
    "    return Tree_ShadowBox_Coords, Tree_ShadowBoxExtend_Coords\n",
    "\n",
    "#Facade shade\n",
    "def Get_FacadeShadePoints(TreeShadow, PrimaryBuilding_IdArr, Building_coords_dict):\n",
    "\n",
    "    FacadeShade_Points = []\n",
    "\n",
    "    RemainingShadow_Points = TreeShadow\n",
    "\n",
    "    for B_ID in PrimaryBuilding_IdArr:\n",
    "\n",
    "        #get the sampled building footprint points\n",
    "        bf_points = Building_coords_dict[B_ID]\n",
    "\n",
    "        #Get only points from BF\n",
    "        BuildingFootprint_shape = alphashape.alphashape(bf_points, alpha=0)\n",
    "\n",
    "        curr_BF_bool_list = []\n",
    "        #find Tree Shadow Points in StreetShade\n",
    "        for tsp in RemainingShadow_Points:\n",
    "            tp = Point(tsp)\n",
    "            curr_BF_bool_list.append(tp.within(BuildingFootprint_shape))\n",
    "        \n",
    "        for fp in RemainingShadow_Points[curr_BF_bool_list]: #only inside the BF shape\n",
    "            FacadeShade_Points.append(fp)\n",
    "        \n",
    "        RemainingShadow_Points = RemainingShadow_Points[~np.array(curr_BF_bool_list)]\n",
    "    \n",
    "    return RemainingShadow_Points, FacadeShade_Points\n",
    "\n",
    "def Get_InShadePoints(TreeShadow, All_Building_LidarPointsDict_HAdj, Az, Amp):\n",
    "\n",
    "    InShade_Points = []\n",
    "    RemainingShadow_Points = TreeShadow\n",
    "\n",
    "    for B_ID, B_lidarpoints in All_Building_LidarPointsDict_HAdj.items():\n",
    "\n",
    "        B_Shadow = Get_Shadow(B_lidarpoints, Az, Amp)\n",
    "\n",
    "        #Get only points from BS\n",
    "        BuildingShadow_shape = alphashape.alphashape(B_Shadow, alpha=0)\n",
    "\n",
    "        curr_BS_bool_list = []\n",
    "        #find Tree Shadow Points in InShade\n",
    "        for tsp in RemainingShadow_Points:\n",
    "            tp = Point(tsp)\n",
    "            curr_BS_bool_list.append(tp.within(BuildingShadow_shape))\n",
    "        \n",
    "        for Ip in RemainingShadow_Points[curr_BS_bool_list]: #only inside the BS shape\n",
    "            InShade_Points.append(Ip)\n",
    "            \n",
    "        if(len(curr_BS_bool_list) > 0):\n",
    "            RemainingShadow_Points = RemainingShadow_Points[~np.array(curr_BS_bool_list)]\n",
    "    \n",
    "    return RemainingShadow_Points, InShade_Points\n",
    "\n",
    "def InitiateShadingLogger(filename:str,year:int)-> None:\n",
    "\n",
    "    LoggerPath = \"Datasets/\"+\"Package_Generated/TEST_DIR/\"+filename[:-4]+\"/\"+str(year)+\"/Shading_Logs_\"+filename[:-4]+\"/\"\n",
    "\n",
    "    print(\"Logger Folder Path : \",LoggerPath)\n",
    "    # Check whether the specified pptk_capture_path exists or not\n",
    "    isExist = os.path.exists(LoggerPath)\n",
    "\n",
    "    if not isExist:\n",
    "    # Create a new directory because it does not exist \n",
    "        os.makedirs(LoggerPath)\n",
    "\n",
    "    logfilename = LoggerPath + filename[:-4]+'.log' \n",
    "    logger = logging.getLogger()\n",
    "    fhandler = logging.FileHandler(filename=logfilename, mode='a')\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fhandler.setFormatter(formatter)\n",
    "    logger.addHandler(fhandler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "def parse_log_Completedfiles(log_file_path):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        log_file_path (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \n",
    "    Usage:\n",
    "    log_file_path = 'TEST_log.log'\n",
    "    filenames = parse_log_Completedfiles(log_file_path)\n",
    "    print(filenames)\n",
    "    \"\"\"\n",
    "    filenames = []\n",
    "    with open(log_file_path, 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            match = re.search(r'(?<=Completed file: )\\S+', line)\n",
    "            if match:\n",
    "                filenames.append(match.group())\n",
    "    return filenames\n",
    "\n",
    "def Get_dirnames(parent_path:str)->list:\n",
    "    dirnames = [d for d in os.listdir(parent_path) if os.path.isdir(os.path.join(parent_path, d))]\n",
    "    return dirnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPotential count of shading files\\n24 hrs at 15 min intervals - 24 x 4\\nCount of trees on average - 2500\\nNumber of lidar files in 2017 - 2000\\nyear round = 365 x 24 x 4 x 2500(including parks) x 2000 = 1.752e^11 files - BIG DATA :D?\\n'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:\n",
    "\"\"\"\n",
    "Potential count of shading files\n",
    "24 hrs at 15 min intervals - 24 x 4\n",
    "Count of trees on average - 2500\n",
    "Number of lidar files in 2017 - 2000\n",
    "year round = 365 x 24 x 4 x 2500(including parks) x 2000 = 1.752e^11 files - BIG DATA :D?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileCount : 14 .las files found in path = Datasets/Package_Generated/\n",
      "[('915127', 2017, 'Datasets/Package_Generated/'), ('7160', 2017, 'Datasets/Package_Generated/'), ('7157', 2017, 'Datasets/Package_Generated/'), ('927162', 2017, 'Datasets/Package_Generated/'), ('927165', 2017, 'Datasets/Package_Generated/'), ('915132', 2017, 'Datasets/Package_Generated/'), ('25192', 2017, 'Datasets/Package_Generated/'), ('922132', 2017, 'Datasets/Package_Generated/'), ('922135', 2017, 'Datasets/Package_Generated/'), ('7155', 2017, 'Datasets/Package_Generated/'), ('7162', 2017, 'Datasets/Package_Generated/'), ('TEST_DIR', 2017, 'Datasets/Package_Generated/'), ('927167', 2017, 'Datasets/Package_Generated/'), ('915130', 2017, 'Datasets/Package_Generated/')]\n"
     ]
    }
   ],
   "source": [
    "#TEST SCRIPT - LOGS in TEST Directory - modify to Dataset paths with original files for deployment\n",
    "\n",
    "script_start_time = time.time()\n",
    "\n",
    "#Get las directory names from parent root folder\n",
    "p_rootpath = \"Datasets/Package_Generated/\" #'/Volumes/Elements/TerraVide/Datasets/FTP_files/LiDAR/'\n",
    "year = 2017\n",
    "\n",
    "LAS_dirnames = Get_dirnames(p_rootpath)\n",
    "\n",
    "print(\"FileCount : \"+str(len(LAS_dirnames))+\" .las files found in path = \"+p_rootpath )\n",
    "\n",
    "args = [(i, year,p_rootpath) for i in LAS_dirnames]#testing for first 2 files\n",
    "\n",
    "print(args)\n",
    "\n",
    "# with Pool(2) as p:\n",
    "\n",
    "#         p.starmap(ProcessShading,args)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = '25192.las'\n",
    "year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger Folder Path :  Datasets/Package_Generated/TEST_DIR/25192.las/2017/Shading_Logs_25192.las/\n"
     ]
    }
   ],
   "source": [
    "InitiateShadingLogger(f,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"TerraVide lidar Shading Metrics Estimation Initated\")\n",
    "#To scale\n",
    "las_file_path = 'Datasets/Package_Generated/'+f[:-4]+'/'+str(year)+'/LasClassified_'+f[:-4]+'/lasFile_Reconstructed_'+f[:-4]+'.las'\n",
    "\n",
    "#To test\n",
    "#las_file_path = 'Datasets/FTP_files/LiDAR/NYC_2017/25192.las'\n",
    "\n",
    "logging.info(\"Reading Reconstructed lasfile from : %s\",las_file_path)\n",
    "\n",
    "#Create a dataframe from las file\n",
    "lasdf = Create_Dataframe_fromLas(las_file_path)\n",
    "\n",
    "lasdf.X = lasdf.X*3.28\n",
    "lasdf.Y = lasdf.Y*3.28\n",
    "lasdf.Z = lasdf.Z*3.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen_las = laspy.read(las_file_path)\n",
    "\n",
    "# Xscale = Gen_las.header.x_scale\n",
    "# Yscale = Gen_las.header.y_scale\n",
    "# Zscale = Gen_las.header.z_scale\n",
    "\n",
    "# Xoffset = Gen_las.header.x_offset\n",
    "# Yoffset = Gen_las.header.y_offset\n",
    "# Zoffset = Gen_las.header.z_offset\n",
    "\n",
    "# Gen_lidarpoints = np.array(\n",
    "#     ( (Gen_las.X*1.00) + Xoffset,  # convert ft to m and correct measurement\n",
    "#     (Gen_las.Y*1.00) + Yoffset,\n",
    "#     (Gen_las.Z*1.00) + Zoffset,\n",
    "#     Gen_las.intensity,\n",
    "#     Gen_las.classification,\n",
    "#     Gen_las.return_number, \n",
    "#     Gen_las.number_of_returns)).transpose()\n",
    "# G_lidar_df = pd.DataFrame(Gen_lidarpoints , columns=['X','Y','Z','intensity','classification','return_number','number_of_returns'])\n",
    "\n",
    "# G_las_Gpoints = G_lidar_df.iloc[:,:3][G_lidar_df[\"classification\"] == 1].to_numpy()\n",
    "# G_las_Tpoints = G_lidar_df.iloc[:,:3][G_lidar_df[\"classification\"] == 2].to_numpy()\n",
    "# G_las_SRpoints = G_lidar_df.iloc[:,:3][G_lidar_df[\"classification\"] == 3].to_numpy()\n",
    "# G_las_NTpoints = G_lidar_df.iloc[:,:3][G_lidar_df[\"classification\"] == 4].to_numpy()\n",
    "# G_las_NCpoints = G_lidar_df.iloc[:,:3][G_lidar_df[\"classification\"] == 5].to_numpy()\n",
    "\n",
    "# #plotting inlier and outlier\n",
    "# All_points_1 = np.concatenate((G_las_Gpoints, G_las_Tpoints,G_las_SRpoints,G_las_NTpoints,G_las_NCpoints), axis=0)\n",
    "# rgb_Ground =  [[1,0,0]]*len(G_las_Gpoints) #Set red colour\n",
    "# rgb_Tree = [[0,1,0]]*len(G_las_Tpoints) #set green colour\n",
    "# rgb_SR = [[0,0,1]]*len(G_las_SRpoints) #set blue colour\n",
    "# rgb_NT = [[255,255,255]]*len(G_las_NTpoints) #set white colour\n",
    "# rgb_NC = [[255,255,0]]*len(G_las_NCpoints) #set cyan colour\n",
    "# All_rgb = np.concatenate((rgb_Ground, rgb_Tree,rgb_SR,rgb_NT,rgb_NC), axis=0)\n",
    "\n",
    "# #Red - Inlier - ground plane , Green - Outlier\n",
    "# v = pptk.viewer(All_points_1, All_rgb)\n",
    "# v.set(show_grid=False)\n",
    "# v.set(show_axis=False)\n",
    "# v.set(bg_color = [0,0,0,1])\n",
    "# v.set(point_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON tree data\n",
    "def Get_filenames(folder_path:str, year:int)->list:\n",
    "    filenames = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    return filenames\n",
    "\n",
    "JSON_TreeData_path = 'Datasets/Package_Generated/'+f[:-4]+'/'+str(year)+'/JSON_TreeData_'+f[:-4]+'/'\n",
    "JSON_filenames = Get_filenames(JSON_TreeData_path,2017)\n",
    "\n",
    "# CSV header\n",
    "header = ['DateTime_ISO', 'Year', 'Month', 'Day', 'hour', 'minute', 'Sun_Azimuth', 'Sun_Amplitude',\n",
    "         'Tree_Number', 'Tree_Latitude', 'Tree_Longitude',\n",
    "         'Shadow_Length','Shadow_Breadth','Shadow_Area','TreeShadow_PointCount',\n",
    "         'Perc_Canopy_StreetShade', 'Perc_Canopy_FacadeShade', 'Perc_Canopy_InShade',\n",
    "         'ShadowArea_Ground', 'ShadowArea_OnBuilding', 'ShadowArea_InBuildingShadow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pptk.viewer(json_SingleTreeDataBuffer['Tree_Points']) #max(np.array(json_SingleTreeDataBuffer['Tree_Points'])[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions rewritten\n",
    "def Get_TreeLocation(json_dataBuffer):\n",
    "    lat = json_dataBuffer['PredictedTreeLocation']['Latitude']\n",
    "    lon = json_dataBuffer['PredictedTreeLocation']['Longitude']\n",
    "    return lat,lon\n",
    "\n",
    "def Get_TreeGroundElevation(json_dataBuffer):\n",
    "    return json_dataBuffer['GroundZValue']\n",
    "\n",
    "def Get_TreeHeight(json_dataBuffer):\n",
    "    return json_dataBuffer['TreeFoliageHeight']\n",
    "\n",
    "def Get_FullTree_points(json_dataBuffer, Ground_Elevation = 0, Tree_Height = 0):\n",
    "    Full_Tree = []\n",
    "    \n",
    "    #TODO : might be doing repetitive conversion here\n",
    "    All_SingleTree_points = np.array(json_dataBuffer['Tree_Points'])*3.28 # Convert m to ft\n",
    "    for p in All_SingleTree_points:\n",
    "        Full_Tree.append(p - [0,0,Ground_Elevation+Tree_Height]) #Height Adjusted, default = 0\n",
    "            \n",
    "    return np.array(Full_Tree)\n",
    "\n",
    "def Get_TreesNotPark(json_filenames, JSON_TreeData_path):\n",
    "    JsonFiles_notInPark = []\n",
    "    for jf in json_filenames:\n",
    "        json_filobj = open(JSON_TreeData_path + jf)\n",
    "        json_SingleTreeDataBuffer = json.load(json_filobj)\n",
    "        if not json_SingleTreeDataBuffer['InPark']:\n",
    "            JsonFiles_notInPark.append(jf)\n",
    "    \n",
    "    return JsonFiles_notInPark\n",
    "\n",
    "def Get_AllTreePoints_from_JSONfiles(json_filenames):\n",
    "    tree_p = []\n",
    "    for jf in json_filenames:\n",
    "        json_filobj = open(JSON_TreeData_path + jf)\n",
    "        json_SingleTreeDataBuffer = json.load(json_filobj)\n",
    "\n",
    "        singleTreePoints = json_SingleTreeDataBuffer['Tree_Points']\n",
    "\n",
    "        for p in singleTreePoints:\n",
    "            tree_p.append(p)\n",
    "    \n",
    "    return tree_p\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_filenamesNotPark = Get_TreesNotPark(JSON_filenames, JSON_TreeData_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(JSON_filenamesNotPark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_TreePointsNotPark = Get_AllTreePoints_from_JSONfiles(JSON_filenamesNotPark[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "TreeID_filename_map = {} #filename -> index in JSON_filenamesNotPark\n",
    "for i,jf in enumerate(JSON_filenamesNotPark):\n",
    "    tree_id = jf.split('_')[3]\n",
    "    if tree_id not in TreeID_filename_map:\n",
    "        TreeID_filename_map[tree_id] = i\n",
    "\n",
    "#sort by keys\n",
    "myKeys = list(TreeID_filename_map.keys())\n",
    "myKeys.sort()\n",
    "sorted_dict = {i: TreeID_filename_map[i] for i in myKeys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for jf in JSON_filenames[0]:\n",
    "#Reading a single file\n",
    "tree_index = 37\n",
    "tree_ID = sorted_dict[list(sorted_dict.keys())[tree_index]]\n",
    "json_filobj = open(JSON_TreeData_path + JSON_filenames[tree_ID])\n",
    "json_SingleTreeDataBuffer = json.load(json_filobj)\n",
    "\n",
    "#test - where is the tree selected located\n",
    "\n",
    "p1 = Raw_TreePointsNotPark\n",
    "p2 = json_SingleTreeDataBuffer['Tree_Points']\n",
    "All_points_1 = np.concatenate((p1, p2), axis=0)\n",
    "rgb_p1 =  [[1,0,0]]*len(p1) #Set red colour\n",
    "rgb_p2 = [[255,255,255]]*len(p2) #set green colour - Classified tree points\n",
    "All_rgb = np.concatenate((rgb_p1, rgb_p2,), axis=0)\n",
    "\n",
    "v = pptk.viewer(All_points_1, All_rgb)\n",
    "v.set(show_grid=False)\n",
    "v.set(show_axis=False)\n",
    "v.set(bg_color = [0,0,0,1])\n",
    "v.set(point_size = 0.04)\n",
    "time.sleep(1)\n",
    "v.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('25192_2017_ID_837_TreeCluster.json',\n",
       " dict_keys(['lasFileName', 'RecordedYear', 'Tree_CountId', 'MR_points', 'SR_points', 'Tree_Points', 'PredictedTreeLocation', 'TreeFoliageHeight', 'GroundZValue', 'ClusterCentroid', 'ConvexHull_MRDict', 'ConvexHull_SRDict', 'ConvexHull_TreeDict', 'InPark']),\n",
       " 837,\n",
       " True,\n",
       " {'Latitude': 40.69898339445048, 'Longitude': -73.8491787595113},\n",
       " 23.001817338334266)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print values\n",
    "JSON_filenames[tree_ID], json_SingleTreeDataBuffer.keys(), json_SingleTreeDataBuffer['Tree_CountId'], json_SingleTreeDataBuffer['InPark'],json_SingleTreeDataBuffer['PredictedTreeLocation'],\\\n",
    "json_SingleTreeDataBuffer['GroundZValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31135531135531136, 0.0, 0.6886446886446886)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATE\n",
    "year = DATE_DICT['YEAR']\n",
    "month = DATE_DICT['MONTH']\n",
    "day = DATE_DICT['DAY']\n",
    "#specific hour and minute\n",
    "hour = 8\n",
    "minute = 30\n",
    "\n",
    "#Tree Data\n",
    "Tree_Lat , Tree_Long = Get_TreeLocation(json_SingleTreeDataBuffer)\n",
    "Tree_GroundZ = Get_TreeGroundElevation(json_SingleTreeDataBuffer) #Convert to ft, JSON file has m stored\n",
    "Tree_Height = Get_TreeHeight(json_SingleTreeDataBuffer)\n",
    "\n",
    "# GET AZ and Amp\n",
    "date, Az, Amp = Get_SunData(Tree_Lat, Tree_Long, year, month, day, hour, minute)\n",
    "\n",
    "#Get Tree Points\n",
    "Full_Tree = Get_FullTree_points(json_SingleTreeDataBuffer,Tree_GroundZ)\n",
    "\n",
    "#Proj_Tree = get_projection(Full_Tree, 45, True)\n",
    "TreeShadow = Get_Shadow(Full_Tree, Az, Amp) #(points, az, amp)\n",
    "\n",
    "BuildingFilePath = 'Datasets/BuildingTileSet/buildingsTile25192.geojson'\n",
    "\n",
    "BuildingFootprints = Get_BuildingFootprint(BuildingFilePath)\n",
    "Building_coords_dict = Get_BuildingDataDict(BuildingFilePath)\n",
    "\n",
    "#Get Primary Building IDs\n",
    "#PrimaryBuilding_IdArr = Get_BuildingsUnderEffectOfShadow(Building_coords_dict, TreeShadow)\n",
    "PrimaryBuilding_IdArr = Get_BuildingsUnderEffectOfShadow_Rapid(Building_coords_dict, TreeShadow) #Function is 50% faster\n",
    "#Get Primary Building Coords\n",
    "PrimaryBuilding_FootprintCoords = Get_BuildingFootprintSampledCoords(PrimaryBuilding_IdArr, Building_coords_dict)\n",
    "\n",
    "#Get Primary Building Lidar Points\n",
    "PrimaryBuilding_LidarPointsDict = Get_BuildingLidarPoints(PrimaryBuilding_IdArr, Building_coords_dict, lasdf)\n",
    "\n",
    "#Get ground elevation from building points\n",
    "G_height = Tree_GroundZ #NOTE : Same as Tree_GroundZ\n",
    "#Adjusting height of Buildings\n",
    "PrimaryBuilding_LidarPointsDict_HAdj = Set_BuildingLidarHeightAdjustment(PrimaryBuilding_LidarPointsDict, G_height)\n",
    "\n",
    "#Bounding Box\n",
    "Distance = 200\n",
    "Tree_ShadowBox_Coords, Tree_ShadowBoxExtend_Coords = Get_TreeShadowBoundingBoxesCoords(TreeShadow, Distance)\n",
    "TSBox = sample_polygon(Tree_ShadowBox_Coords)\n",
    "TSBox = np.c_[TSBox, np.zeros(len(TSBox))]\n",
    "TSBoxExtend = sample_polygon(Tree_ShadowBoxExtend_Coords)\n",
    "TSBoxExtend = np.c_[TSBoxExtend, np.zeros(len(TSBoxExtend))]\n",
    "\n",
    "#Get All buildings Falling under Extended Tree ShadowBox\n",
    "All_Building_IdArr = Get_BuildingsUnderEffectOfShadow_Rapid(Building_coords_dict, TSBoxExtend)\n",
    "#Get Secondary Building Lidar Points\n",
    "All_Building_LidarPointsDict = Get_BuildingLidarPoints(All_Building_IdArr, Building_coords_dict, lasdf)\n",
    "#Get ground elevation from building points\n",
    "G_height = Tree_GroundZ #NOTE : Same as Tree_GroundZ\n",
    "#Adjusting height of Buildings\n",
    "All_Building_LidarPointsDict_HAdj = Set_BuildingLidarHeightAdjustment(All_Building_LidarPointsDict, G_height)\n",
    "\n",
    "#Get Secondary Buildings\n",
    "SecondaryBuilding_IdArr = [b for b in All_Building_IdArr if b not in PrimaryBuilding_IdArr]\n",
    "#Get Secondary Building Coords\n",
    "SecondaryBuilding_FootprintCoords = Get_BuildingFootprintSampledCoords(SecondaryBuilding_IdArr, Building_coords_dict)\n",
    "#Get Secondary Building Lidar Points\n",
    "SecondaryBuilding_LidarPointsDict = Get_BuildingLidarPoints(SecondaryBuilding_IdArr, Building_coords_dict, lasdf)\n",
    "#Get ground elevation from building points\n",
    "G_height = Tree_GroundZ #NOTE : Same as Tree_GroundZ\n",
    "#Adjusting height of Buildings\n",
    "SecondaryBuilding_LidarPointsDict_HAdj = Set_BuildingLidarHeightAdjustment(SecondaryBuilding_LidarPointsDict, G_height)\n",
    "\n",
    "# Shade Metrics\n",
    "\n",
    "# 1. Facade Shade - Points falling on the building footprint\n",
    "# 2. In Shade - Points Fall within the shadow of Buildings not in the building footprint\n",
    "# 3. Street Shade - Tree Shadow Points not overcasted by Anything\n",
    "RemainingShadow_Points, FacadeShade_Points = Get_FacadeShadePoints(TreeShadow, PrimaryBuilding_IdArr, Building_coords_dict)\n",
    "RemainingShadow_Points, InShade_Points = Get_InShadePoints(RemainingShadow_Points, All_Building_LidarPointsDict_HAdj, Az, Amp)\n",
    "StreetShade_Points = RemainingShadow_Points\n",
    "\n",
    "len(FacadeShade_Points)/len(TreeShadow) , len(InShade_Points)/len(TreeShadow) ,len(StreetShade_Points)/len(TreeShadow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BuildingFootprints.shape,Full_Tree.shape,TreeShadow.shape,B_lidarP.shape, B_lidarS.shape, np.array(FacadeShade_Points).shape, np.array(InShade_Points).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE : Ensure all values are populated before plot\n",
    "\n",
    "#commented for plot test\n",
    "B_lidarP = (np.concatenate(list(PrimaryBuilding_LidarPointsDict_HAdj.values())))\n",
    "B_lidarS = (np.concatenate(list(SecondaryBuilding_LidarPointsDict_HAdj.values())))\n",
    "\n",
    "#ALL_points = np.concatenate((BuildingFootprints,Full_Tree,TreeShadow,B_lidarP, B_lidarS, FacadeShade_Points, InShade_Points, StreetShade_Points), axis=0)\n",
    "ALL_points_test = np.concatenate((BuildingFootprints,Full_Tree,TreeShadow,B_lidarP, B_lidarS), axis=0)\n",
    "\n",
    "rgb_BuildingFootprints =  [[255,255,255]]*len(BuildingFootprints) #Set red colour\n",
    "rgb_Full =  [[1,0,0]]*len(Full_Tree) #Set red colour\n",
    "rgb_Proj = [[0,1,0]]*len(TreeShadow) #set green colour\n",
    "rgb_B_lidarP = [[150,220,60]]*len(B_lidarP) \n",
    "rgb_B_lidarS = [[200,200,0]]*len(B_lidarS) \n",
    "rgb_FacadeShadePoints  = [COLOR_DICT['YELLOW']]*len(FacadeShade_Points)\n",
    "rgb_InShadePoints = [COLOR_DICT['LIGHT_BLUE']]*len(InShade_Points)\n",
    "rgb_StreetShadePoints = [COLOR_DICT['PINK']]*len(StreetShade_Points)\n",
    "#All_rgb = np.concatenate((rgb_BuildingFootprints,rgb_Full, rgb_Proj,rgb_B_lidarP,rgb_B_lidarS, rgb_FacadeShadePoints, rgb_InShadePoints, rgb_StreetShadePoints), axis=0)\n",
    "All_rgb_test = np.concatenate((rgb_BuildingFootprints,rgb_Full, rgb_Proj,rgb_B_lidarP,rgb_B_lidarS), axis=0)\n",
    "\n",
    "#Red - MR , Green - SR\n",
    "v = pptk.viewer(ALL_points_test, All_rgb_test)\n",
    "v.set(show_grid=False)\n",
    "v.set(show_axis=False)\n",
    "v.set(bg_color = [0,0,0,0])\n",
    "v.set(point_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_end_time = time.time()\n",
    "\n",
    "print(\"SCRIPT TOTAL TIME (in min): \",(script_end_time - script_start_time)/60)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "395b5501581aedb2d94c1f1944a406c3cb0aeb8faa5df16e5001f1dc5b0910fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
